import numpy as np
import matplotlib.pyplot as plt

# 1) PARAMETERS
phi1, phi2 = 0.8, 0.5       # imbalance decay factors
lambda_   = 0.1             # imbalance penalty weight
T         = 390             # minutes until close
n_alpha   = 3               # number of alphas

# 2) ALPHA AR(1) DYNAMICS (given)
Rho = np.array([[0.9, 0.1, 0.0],
                [0.0, 0.7, 0.2],
                [0.0, 0.0, 0.5]])
Sigma_alpha = 0.01 * np.eye(n_alpha)

# 3) BUILD STATE-SPACE MATRICES
# state s = [ p, imb1, imb2, alpha1, alpha2, alpha3 ]ᵀ
n = 1 + 2 + n_alpha
F = np.zeros((n,n))
F[0,0]   = 1         # p_{t+1} = p_t + x_t
F[1,1]   = phi1      # imb1_{t+1} = φ1·imb1_t + ...
F[2,2]   = phi2      # imb2_{t+1} = φ2·imb2_t + ...
F[3:,3:] = Rho       # α_t dynamics

G = np.zeros((n,1))
G[0,0] = 1
G[1,0] = 1 - phi1
G[2,0] = 1 - phi2

# 4) INSTANTANEOUS COST ℓ(s,x) = ½(p+x)² − (α₁/30)(p+x) + ½λ(imb1_{t+1}+imb2_{t+1})·x
#    in LQ form ℓ = ½ sᵀ Q s + sᵀ N x + ½ R x²

Q = np.zeros((n,n))
Q[0,0] = 1                      # ½ p² term
# cross-term for −(α₁/30)·p: ½·2·Q[0,3]·p·α₁ = −(α₁/30)·p
Q[0,3] = Q[3,0] = -1/30        

N = np.zeros((n,1))
# from p·x term in ½(p+x)² → p·x
N[0,0] = 1.0                   
# from −(α₁/30)·x term
N[3,0] = -1/30                 
# from ½·λ·(φ₁·imb1 + φ₂·imb2)·x
N[1,0] = 0.5 * lambda_ * phi1  
N[2,0] = 0.5 * lambda_ * phi2  

# R = 1/2·2·x² from ½(p+x)² plus ½·λ·(2−φ₁−φ₂)·x²
R = 1.0 + lambda_ * (2 - (phi1 + phi2))

# 5) TERMINAL COST V_T(s) = −p_T·(imb1_T+imb2_T) = ½ sᵀ Qf s
Qf = np.zeros((n,n))
Qf[0,1] = Qf[1,0] = -0.5
Qf[0,2] = Qf[2,0] = -0.5

# 6) BACKWARD RICCATI PASS → P_t, K_t, r_t
P = [None]*(T+1)
r = np.zeros(T+1)
K = [None]*T

# full noise covariance (only alphas noisy)
Sigma_full = np.zeros((n,n))
Sigma_full[3:,3:] = Sigma_alpha

# terminal condition
P[T] = Qf
r[T] = 0.0

for t in reversed(range(T)):
    H    = float(R + (G.T @ P[t+1] @ G))          # scalar
    K[t] = ((G.T @ P[t+1] @ F + N.T) / H)         # shape (1,n)
    P[t] = (Q
            + F.T @ P[t+1] @ F
            - (F.T @ P[t+1] @ G + N) @ K[t])     # Riccati update
    r[t] = r[t+1] + 0.5 * np.trace(P[t+1] @ Sigma_full)

# 7) SIMULATION WITH x_t = −K_t·s_t
np.random.seed(0)
s = np.zeros((n,1))
xs, values, rewards = [], [], []

for t in range(T):
    # optimal action
    x = float(-K[t] @ s)
    xs.append(x)

    # value function V_t(s) = sᵀP_t s + r[t]
    values.append(float(s.T @ P[t] @ s) + r[t])

    # compute instantaneous reward for monitoring
    p, i1, i2 = s[0,0], s[1,0], s[2,0]
    a1 = s[3,0]
    p_next   = p + x
    im1_next = phi1*i1 + (1-phi1)*x
    im2_next = phi2*i2 + (1-phi2)*x
    rew = (a1/30)*p_next - 0.5*p_next**2 - 0.5*lambda_*(im1_next+im2_next)*x
    rewards.append(rew)

    # state update with Gaussian noise on alphas only
    eps = np.zeros((n,1))
    eps[3:,0] = np.random.multivariate_normal(np.zeros(n_alpha), Sigma_alpha)
    s = F @ s + G*x + eps

# 8) DIAGNOSTICS
print("Final cumulative position:", sum(xs))
plt.figure(figsize=(12,4))
plt.subplot(1,3,1)
plt.plot(np.cumsum(xs));  plt.title("Cumulative Position");  plt.grid(True)
plt.subplot(1,3,2)
plt.plot(values);         plt.title("Value V_t(s_t)");      plt.grid(True)
plt.subplot(1,3,3)
plt.plot(np.cumsum(rewards)); plt.title("Cumulative Reward"); plt.grid(True)
plt.tight_layout()
plt.show()