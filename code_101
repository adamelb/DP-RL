import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

# --- 1) Define ValueMLP with normalization buffers and a learnable shift ---
class ValueMLP(nn.Module):
    def __init__(self, input_dim, zero=False):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 256), nn.ReLU(), nn.Dropout(0.4),
            nn.Linear(256, 256), nn.ReLU(), nn.Dropout(0.4),
            nn.Linear(256, 256), nn.ReLU(), nn.Dropout(0.4),
            nn.Linear(256,   1)
        )
        if zero:
            for p in self.parameters():
                nn.init.zeros_(p)
        # buffers for global target‐normalization
        self.register_buffer('mean_q', torch.tensor(0.0))
        self.register_buffer('std_q',  torch.tensor(1.0))
        # learnable shift to recover the mean
        self.shift = nn.Parameter(torch.tensor(0.0))

    def forward(self, phi):
        # phi is already normalized input features
        q_norm = self.net(phi).squeeze(-1)
        # de‐normalize and add shift
        return q_norm * self.std_q + self.mean_q + self.shift

    def set_normalization(self, mean_q_value, std_q_value):
        self.mean_q.copy_(torch.as_tensor(mean_q_value, device=self.mean_q.device))
        self.std_q.copy_( torch.as_tensor(std_q_value,  device=self.std_q.device))


# --- 2) Instantiate model & target, freeze target ---
input_dim = f               # number of input features
DEVICE    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
gamma     = 0.99

model = ValueMLP(input_dim).to(DEVICE)
target_model = ValueMLP(input_dim).to(DEVICE)
target_model.load_state_dict(model.state_dict())
for p in target_model.parameters():
    p.requires_grad = False


# --- 3) Precompute Bellman targets and global normalization ---
# Assume you have tensors for your entire dataset:
#   `states`       of shape (N, state_dim)
#   `next_states`  of shape (N, state_dim)
#   `rewards`      of shape (N,)
# and `features()` that maps a state -> feature vector of length input_dim
# also precomputed `feat_mean`, `feat_std` for input normalization

# Normalize next‐state features
phi_next_all = (features(next_states) - feat_mean) / feat_std

# Compute raw Bellman targets
with torch.no_grad():
    Q_next_all = target_model(phi_next_all)           # real‐scale Q(s')
Q_target_raw_all = rewards + gamma * Q_next_all      # B(target_model)

# Compute global mean & std of these targets
mean_q = Q_target_raw_all.mean().item()
std_q  = Q_target_raw_all.std().item()

# Tell our model about the normalization
model.set_normalization(mean_q, std_q)


# --- 4) Build a DataLoader for (state, Q_target_raw) ---
dataset = torch.utils.data.TensorDataset(states, Q_target_raw_all)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)


# --- 5) Mini training loop fitting B(target_model) ---
optimizer = optim.Adam(model.parameters(), lr=1e-4)
n_epochs = 10

for epoch in range(n_epochs):
    model.train()
    for state_batch, Q_raw_batch in dataloader:
        state_batch = state_batch.to(DEVICE)
        Q_raw_batch = Q_raw_batch.to(DEVICE)

        # normalize inputs
        phi = (features(state_batch) - feat_mean) / feat_std

        # forward & compute loss on raw targets
        Q_pred = model(phi)
        loss = F.mse_loss(Q_pred, Q_raw_batch)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    # After each epoch (or outer iteration), sync target_model if needed:
    target_model.load_state_dict(model.state_dict())
    target_model.eval()