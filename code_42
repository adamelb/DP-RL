# ==========================================================
#  Value-Function Learning pour 3 actions avec impact linÃ©aire
# ==========================================================
#
#  * Inventaire       p  âˆˆ â„Â³
#  * Alpha (signal)   Î±  âˆˆ â„Â³   â€ƒ AR(1) avec coeffs Ï
#  * Impact rÃ©siduel  i  âˆˆ â„Â³   â€ƒ iâ‚œâ‚Šâ‚ = Ï† âŠ™ iâ‚œ + k âŠ™ xâ‚œ
#
#  RÃ©compense instantanÃ©e
#      r(s,x) = Î±áµ€(p+x) âˆ’ cÂ·|x| âˆ’ Â½ xáµ€(t+k)x âˆ’ Â½ Î» (p+x)áµ€Î£(p+x) âˆ’ iáµ€x
#
#  V(s) = maxâ‚“  r(s,x) + Î³ ð”¼[V(s')]
#
# ----------------------------------------------------------
import itertools, math, time, copy, random, functools
import numpy as np
import torch
import torch.nn as nn
from torch.distributions import Normal, MultivariateNormal

# ---------- 1. Configuration gÃ©nÃ©rale ---------------------------------------
SEED               = 0
torch.manual_seed(SEED)
np.random.seed(SEED)

DEVICE             = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

DIM                = 3                    # nombre dâ€™actions
GAMMA              = 0.99                 # facteur dâ€™actualisation
LAMBDA_RISK        = 1.0                  # aversion au risque Î»
N_DATASET          = 30_000               # Ã©tats tirÃ©s hors-ligne
BATCH_SIZE         = 512
N_EPOCHS           = 50
LR                 = 2e-3
WEIGHT_DECAY       = 1e-4                 # L2 sur les poids
N_ACTIONS_1D       = 41                   # grille unidimensionnelle -1â€¦+1
ACTION_GRID_1D     = torch.linspace(-1., 1., N_ACTIONS_1D, device=DEVICE)
ACTION_GRID_CARTE  = torch.tensor(list(itertools.product(
                             ACTION_GRID_1D, ACTION_GRID_1D, ACTION_GRID_1D)),
                             device=DEVICE)                                   # (A,3)
N_ACTIONS          = ACTION_GRID_CARTE.shape[0]

# ---------- 2. GÃ©nÃ©ration dâ€™une matrice de corrÃ©lation Î£ --------------------
def random_correlation_matrix(dim: int = DIM) -> torch.Tensor:
    """
    GÃ©nÃ¨re une matrice de corrÃ©lation SPD via la mÃ©thode de Bendel-Mickey :
    Î£ = QÎ›Qáµ€ puis normalisation -> diag(Î£)=1.
    """
    A = torch.randn(dim, dim)
    Q, _ = torch.linalg.qr(A)
    l = torch.rand(dim) + 0.5          # valeurs propres positives
    Î£   = (Q * l).matmul(Q.T)
    d   = torch.sqrt(torch.diag(Î£))
    Î£   = Î£ / (d.outer(d))             # renormalise en vraies corrÃ©lations
    return Î£.to(DEVICE)

SIGMA = random_correlation_matrix()    # constante pendant tout le run
SIGMA_CHOL = torch.linalg.cholesky(SIGMA)   # pour simuler le bruit

# ---------- 3. Hyper-paramÃ¨tres Ã  tirer alÃ©atoirement -----------------------
RHO_MIN, RHO_MAX = 0.0, 1.0            # autocorrÃ©lation alpha
C_MIN,  C_MAX    = 0.0, 10.0           # coÃ»t linÃ©aire
T_MIN,  T_MAX    = 1.0, 1000.0         # coÃ»t quadratique temporaire
K_MIN,  K_MAX    = 0.0,  1.0           # slippage linÃ©aire
TAU_MIN, TAU_MAX = 1.0, 20.0           # temps de dÃ©croissance de lâ€™impact

# ---------- 4. GÃ©nÃ©ration dâ€™un batch dâ€™Ã©tats hors-ligne ---------------------
@torch.no_grad()
def resample_dataset(n: int = N_DATASET):
    """
    Tire n Ã©tats (p, Î±, i, c, t, k, Ï, Ï„, Ï†) indÃ©pendants ;
    lâ€™impact rÃ©siduel initial iâ‚€ est mis Ã  0 (optionnelment alÃ©atoire).
    """
    p     = torch.empty((n, DIM), device=DEVICE).uniform_(-1., 1.)
    alpha = torch.empty((n, DIM), device=DEVICE).uniform_(-1., 1.)
    impact= torch.zeros_like(p)                           # iâ‚€ = 0 (facultatif : rand)
    c     = torch.empty((n, DIM), device=DEVICE).uniform_(C_MIN,  C_MAX)
    t     = torch.empty((n, DIM), device=DEVICE).uniform_(T_MIN,  T_MAX)
    k     = torch.empty((n, DIM), device=DEVICE).uniform_(K_MIN,  K_MAX)
    rho   = torch.empty((n, DIM), device=DEVICE).uniform_(RHO_MIN, RHO_MAX)
    tau   = torch.empty((n, DIM), device=DEVICE).uniform_(TAU_MIN, TAU_MAX)
    phi   = torch.exp(-1. / tau)                         # Ï† = e^{-1/Ï„}
    return p, alpha, impact, c, t, k, rho, tau, phi

# ---------- 5. Construction de features f(s) --------------------------------
def features(p, alpha, impact, c, t, k, rho, phi):
    """
    ConcatÃ¨ne des composantes invariantes par permutation de signe
    (|.|) et leurs signes afin dâ€™aider le rÃ©seau.
    """
    comps = [
        p, alpha, impact,
        c, t, k, rho, phi,
        torch.abs(p), torch.abs(alpha), torch.abs(impact),
        torch.sign(p), torch.sign(alpha)
    ]
    return torch.cat(comps, dim=-1)                       # shape (..., F)

_F = features(*[torch.zeros((1, DIM), device=DEVICE) for _ in range(8)]).numel()

# ---------- 6. Reward instantanÃ©e r(s,a) ------------------------------------
def reward(alpha, p, impact, x, c, t, k):
    """
    ImplÃ©mente exactement :
        r = Î±áµ€(p+x) âˆ’ cÂ·|x| âˆ’ Â½ xáµ€(t+k) x âˆ’ Â½ Î» (p+x)áµ€ Î£ (p+x) âˆ’ impactáµ€ x
    Î±, p, impact, x, c, t, k : (...,3)
    """
    p_new   = p + x
    lin_co  = (alpha * p_new).sum(dim=-1)
    exec_lin= (c * torch.abs(x)).sum(dim=-1)
    quad    = 0.5 * ((t + k) * x**2).sum(dim=-1)
    risk    = 0.5 * LAMBDA_RISK * \
              torch.einsum('...i,ij,...j->...', p_new, SIGMA, p_new)
    impact_term = (impact * x).sum(dim=-1)
    return lin_co - exec_lin - quad - risk - impact_term   # shape (...)

# ---------- 7. RÃ©seau de valeur V_\theta ------------------------------------
class ValueMLP(nn.Module):
    def __init__(self, dim_in=_F):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(dim_in, 128), nn.ReLU(),
            nn.Linear(128, 128),    nn.ReLU(),
            nn.Linear(128, 128),    nn.ReLU(),
            nn.Linear(128, 1)
        )
    def forward(self, Ï†):      # Ï† shape (batch, _F)
        return self.net(Ï†).squeeze(-1)   # shape (batch,)

# ---------- 8. Pas de dynamique : s --a--> s' -------------------------------
def step_dynamics(p, alpha, impact, x, rho, phi, k):
    """
    Construit le prochain Ã©tat s' donnÃ© s et action x.
    * alpha'  = rho âŠ™ alpha + âˆš(1-rhoÂ²) Îµ   avec Îµ~N(0,Î£)
    * p'      = p + x
    * impact' = phi âŠ™ (impact + k âŠ™ x)
    """
    # bruit gaussien multivariÃ© corrÃ©lÃ©
    Îµ_std = torch.randn_like(alpha) @ SIGMA_CHOL.T      # shape (...,3)
    alpha_next = rho * alpha + torch.sqrt(1. - rho**2) * Îµ_std
    p_next     = p + x
    impact_next= phi * (impact + k * x)
    return p_next, alpha_next, impact_next

# ---------- 9.  Boucle dâ€™entraÃ®nement --------------------------------------
def train_value_function():
    # 9-1  dataset hors-ligne
    p_ds, a_ds, i_ds, c_ds, t_ds, k_ds, rho_ds, tau_ds, phi_ds = resample_dataset()
    N = p_ds.size(0)

    model = ValueMLP().to(DEVICE)
    target = copy.deepcopy(model).eval()
    for p in target.parameters(): p.requires_grad_(False)

    opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
    scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.99)

    start = time.time()
    for epoch in range(1, N_EPOCHS+1):
        perm = torch.randperm(N, device=DEVICE)
        epoch_loss = 0.0
        for batch_start in range(0, N, BATCH_SIZE):
            idx = perm[batch_start:batch_start+BATCH_SIZE]
            p      = p_ds[idx];   alpha = a_ds[idx];  impact = i_ds[idx]
            c      = c_ds[idx];   t     = t_ds[idx];  k      = k_ds[idx]
            rho    = rho_ds[idx]; phi   = phi_ds[idx]

            # ---------- valeurs actuelles ----------------------------------
            Ï†      = features(p, alpha, impact, c, t, k, rho, phi)
            V_pred = model(Ï†)                                        # (B,)

            # ---------- Ã©numÃ©ration des actions (ACTIONS x B) ------------
            #  actions : (A,3)  ->  (B,A,3)
            x_all   = ACTION_GRID_CARTE.unsqueeze(0).expand(p.size(0), -1, -1)

            # broadcast states (B,1,3) -> (B,A,3)
            p_b     = p.unsqueeze(1).expand_as(x_all)
            a_b     = alpha.unsqueeze(1).expand_as(x_all)
            i_b     = impact.unsqueeze(1).expand_as(x_all)
            c_b     = c.unsqueeze(1).expand_as(x_all)
            t_b     = t.unsqueeze(1).expand_as(x_all)
            k_b     = k.unsqueeze(1).expand_as(x_all)
            rho_b   = rho.unsqueeze(1).expand_as(x_all)
            phi_b   = phi.unsqueeze(1).expand_as(x_all)

            # reward immÃ©diat
            r_immed = reward(a_b, p_b, i_b, x_all, c_b, t_b, k_b)   # (B,A)

            # next state
            p_n, a_n, i_n = step_dynamics(p_b, a_b, i_b, x_all, rho_b, phi_b, k_b)
            Ï†_next  = features(p_n, a_n, i_n, c_b, t_b, k_b, rho_b, phi_b)
            Ï†_next  = Ï†_next.view(-1, _F)
            with torch.no_grad():
                v_next = target(Ï†_next).view(p.size(0), N_ACTIONS)   # (B,A)

            q_values = r_immed + GAMMA * v_next                     # (B,A)
            v_target = q_values.max(dim=1).values                   # (B,)

            # ---------- MSE -------------------------------------------------
            loss = nn.functional.mse_loss(V_pred, v_target)
            opt.zero_grad()
            loss.backward()
            opt.step()
            epoch_loss += loss.item() * p.size(0)

        # mise Ã  jour soft du rÃ©seau cible
        with torch.no_grad():
            tau_soft = 0.01
            for Î¸_t, Î¸ in zip(target.parameters(), model.parameters()):
                Î¸_t.data.mul_(1-tau_soft).add_(tau_soft * Î¸.data)

        scheduler.step()
        print(f"[Epoch {epoch:02d}] loss = {epoch_loss/N:.6f}")

    print(f"EntraÃ®nement terminÃ© en {time.time()-start:.1f} s")
    return model

# ----------- 10. Exemple dâ€™appel -------------------------------------------
if __name__ == '__main__':
    trained_model = train_value_function()

    # --- Ã©valuation sur un Ã©tat alÃ©atoire (drawn on the fly) ---------------
    p, alpha, impact, c, t, k, rho, tau, phi = [x[:1] for x in resample_dataset(1)]
    Ï† = features(p, alpha, impact, c, t, k, rho, phi)
    v_hat = trained_model(Ï†)
    print("\nValeur estimÃ©e VÌ‚(s) =", v_hat.item())