import torch
from torch import nn, optim
from torch.utils.data import TensorDataset, DataLoader
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# --- 0. Assume these are already torch.Tensors on CPU or GPU:
# X_train, y_train, X_test, y_test
# Shapes:
#   X_train: [N_train, n_features]
#   y_train: [N_train, 1]      (or [N_train])
#   X_test:  [N_test,  n_features]
#   y_test:  [N_test,  1]      (or [N_test])

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
X_train = X_train.to(device)
y_train = y_train.to(device).view(-1,1)
X_test  = X_test.to(device)
y_test  = y_test.to(device).view(-1,1)

# --- 1. Compute normalization stats on TRAIN only
x_mean = X_train.mean(dim=0, keepdim=True)
x_std  = X_train.std(dim=0, keepdim=True)
y_mean = y_train.mean()
y_std  = y_train.std()

# --- 2. Normalize
X_train_norm = (X_train - x_mean) / x_std
X_test_norm  = (X_test  - x_mean) / x_std

y_train_norm = (y_train - y_mean) / y_std
y_test_norm  = (y_test  - y_mean) / y_std

# --- 3. DataLoaders
batch_size = 32
train_ds = TensorDataset(X_train_norm, y_train_norm)
test_ds  = TensorDataset(X_test_norm,  y_test_norm)
train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
test_loader  = DataLoader(test_ds,  batch_size=batch_size)

# --- 4. Define your model
class MLP(nn.Module):
    def __init__(self, in_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )
    def forward(self, x):
        return self.net(x)

model = MLP(X_train.shape[1]).to(device)

# --- 5. Training setup
optimizer = optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.MSELoss()
n_epochs  = 100

# --- 6. Training loop
for epoch in range(1, n_epochs+1):
    model.train()
    running_loss = 0.0
    for xb, yb in train_loader:
        optimizer.zero_grad()
        preds = model(xb)
        loss = criterion(preds, yb)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * xb.size(0)
    epoch_loss = running_loss / len(train_loader.dataset)
    if epoch % 10 == 0 or epoch == 1:
        print(f"Epoch {epoch:3d} — train MSE (norm): {epoch_loss:.4f}")

# --- 7. Evaluation
model.eval()
with torch.no_grad():
    X_test_all = X_test_norm  # already normalized
    y_pred_norm = model(X_test_all).cpu()

# --- 8. Invert the normalization on predictions & targets
y_pred = y_pred_norm * y_std.item() + y_mean.item()
y_true = y_test.cpu()

# --- 9. Compute metrics in original units
mse = mean_squared_error(y_true, y_pred)
mae = mean_absolute_error(y_true, y_pred)
r2  = r2_score(y_true, y_pred)

print("\n--- Test metrics (original units) ---")
print(f"MSE: {mse:.4f}")
print(f"MAE: {mae:.4f}")
print(f"R²:  {r2:.4f}")